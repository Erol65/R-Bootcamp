{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Export\n",
    "---\n",
    "As you saw in the earlier notebooks some of R packages provide sample data for educational purposes. In the real world we would want to import our own data for analysis. Base R provides functions for reading and exporting data files but it's not as convenient, and fast as some of the other packages available to us. Here we will use the package **readr**, it is a part of *tidyverse* suite so no need to install it since we already have tidyverse. In order to use it we need to load tidyverse (or directly readr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "✔ ggplot2 3.0.0     ✔ purrr   0.2.5\n",
      "✔ tibble  1.4.2     ✔ dplyr   0.7.6\n",
      "✔ tidyr   0.8.1     ✔ stringr 1.3.1\n",
      "✔ readr   1.1.1     ✔ forcats 0.3.0\n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(openxlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading flat files into data frames\n",
    "Under the *data* folder we have a comma-separated value (CSV) file called `Telco-Customer-Churn.csv`. Let's try to load it using `read_csv()` function from readr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_character(),\n",
      "  SeniorCitizen = col_integer(),\n",
      "  tenure = col_integer(),\n",
      "  MonthlyCharges = col_double(),\n",
      "  TotalCharges = col_double()\n",
      ")\n",
      "See spec(...) for full column specifications.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 7,043 x 21\n",
      "   customerID gender SeniorCitizen Partner Dependents tenure PhoneService\n",
      "   <chr>      <chr>          <int> <chr>   <chr>       <int> <chr>       \n",
      " 1 7590-VHVEG Female             0 Yes     No              1 No          \n",
      " 2 5575-GNVDE Male               0 No      No             34 Yes         \n",
      " 3 3668-QPYBK Male               0 No      No              2 Yes         \n",
      " 4 7795-CFOCW Male               0 No      No             45 No          \n",
      " 5 9237-HQITU Female             0 No      No              2 Yes         \n",
      " 6 9305-CDSKC Female             0 No      No              8 Yes         \n",
      " 7 1452-KIOVK Male               0 No      Yes            22 Yes         \n",
      " 8 6713-OKOMC Female             0 No      No             10 No          \n",
      " 9 7892-POOKP Female             0 Yes     No             28 Yes         \n",
      "10 6388-TABGU Male               0 No      Yes            62 Yes         \n",
      "# ... with 7,033 more rows, and 14 more variables: MultipleLines <chr>,\n",
      "#   InternetService <chr>, OnlineSecurity <chr>, OnlineBackup <chr>,\n",
      "#   DeviceProtection <chr>, TechSupport <chr>, StreamingTV <chr>,\n",
      "#   StreamingMovies <chr>, Contract <chr>, PaperlessBilling <chr>,\n",
      "#   PaymentMethod <chr>, MonthlyCharges <dbl>, TotalCharges <dbl>, Churn <chr>\n"
     ]
    }
   ],
   "source": [
    "telcoChurnDf <- read_csv(\"../data/Telco-Customer-Churn.csv\")\n",
    "print(telcoChurnDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I used `\"../data/Telco-Customer-Churn.csv\"` as the path. If you are in your R-Bootcamp RProj you can simply provide the relative path from the parent directory, i.e. `\"data/Telco-Customer-Churn.csv\"`. This is particularly useful because let's say you need to copy this part of your code and use it in a different folder, e.g. sandbox, then you don't need to change the path.\n",
    "\n",
    "As it appears from the look of printed data frame we immediately release that `read_csv()` has automatically loaded our CSV file into a tibble data frameand associated it with the name we provided. We can also check its class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:1:20: unexpected symbol\n1: class(telcoChurnDf)Mohammad\n                       ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:1:20: unexpected symbol\n1: class(telcoChurnDf)Mohammad\n                       ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "class(telcoChurnDf)Mohammad Soltanieh-ha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the help page for `read_csv()` we can see what defaults were used for importing the file:\n",
    "\n",
    "```read_csv(file, col_names = TRUE, col_types = NULL,\n",
    "  locale = default_locale(), na = c(\"\", \"NA\"), quoted_na = TRUE,\n",
    "  quote = \"\\\"\", comment = \"\", trim_ws = TRUE, skip = 0, n_max = Inf,\n",
    "  guess_max = min(1000, n_max), progress = show_progress())```\n",
    "  \n",
    "To get details for each of these parameters scroll down to see descriptions and examples.\n",
    "\n",
    "We started with `read_csv()` since it's by far the most popular *flat file*. But not all the rectangular files have their fields separated by a comma (\",\"). Most common *delimiter-separated values* (DSV) files are: comma (\",\", also CSV), tab (\"    \", also TSV), colon (\";\"), and pipe (\"|\"). `read_delim()` is a generic function that can handle different delimiters, note that the second argument `delim` must be provided:\n",
    "\n",
    "\n",
    "```read_delim(file, delim, quote = \"\\\"\", escape_backslash = FALSE,\n",
    "  escape_double = TRUE, col_names = TRUE, col_types = NULL,\n",
    "  locale = default_locale(), na = c(\"\", \"NA\"), quoted_na = TRUE,\n",
    "  comment = \"\", trim_ws = FALSE, skip = 0, n_max = Inf,\n",
    "  guess_max = min(1000, n_max), progress = show_progress())```\n",
    "\n",
    "There are several different functions to support other formats such as fixed width files, and log files. To learn more visit [readr.tidyverse.org](https://readr.tidyverse.org/)\n",
    "\n",
    "## Reading from inline \n",
    "Any of these functions will work with reading inline instead of a file. This is primarily useful for experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv(\"a,b,c\n",
    "1,2,3\n",
    "4,5,6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDf <- read_csv(\"a,b,c\n",
    "1,2,3\n",
    "4,5,6\")\n",
    "print(sampleDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calDf <- read_delim(\"First 2 lines to be skipped!\n",
    "Calendar for September 2018\n",
    "Mon|Tue|Wed|Thu|Fri|MONTH\n",
    "3|4|5|6|7|September\n",
    "10|11|12|13|14|September\n",
    "17|18|19|20|21|September\n",
    "24|25|26|27|28|September\",\n",
    "delim = \"|\",\n",
    "skip = 2)\n",
    "\n",
    "calDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data might not come with column name, we can tell the function that don't use the first row as column name by `col_names = FALSE`, which is the default behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv(\"1,2,3\\n4,5,6\", col_names = FALSE)Mohammad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_csv()` is providing names for the columns, we can also specify them manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv(\"1,2,3\\n4,5,6\", col_names = c(\"x\", \"y\", \"z\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 1\n",
    "Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like `\"` or `'`. By convention, `read_csv()` assumes that the quoting character will be `\"`, and if you want to change it you'll need to use `read_delim()` instead. What arguments do you need to specify to read the following text into a data frame?\n",
    "\n",
    "> `\"x,y\\n1,'a,b'\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 2\n",
    "Identify what is wrong with each of the following inline CSV files. What happens when you run the code?\n",
    "\n",
    "> ```\n",
    "read_csv(\"a,b\\n1,2,3\\n4,5,6\")\n",
    "read_csv(\"a,b,c\\n1,2\\n1,2,3,4\")\n",
    "read_csv(\"a,b\\n1,2\\na,b\")\n",
    "read_csv(\"a;b\\n1;3\")```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parsing a vector\n",
    "Behind the scene readr is using a series of functions called `parse_*()` to import the columns in the data. For instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_logical(c(\"TRUE\", \"FALSE\", \"NA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_integer(c(\"1\", \"2\", \"3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_date(c(\"2010-01-01\", \"1979-10-14\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the `NA` values as they appear differently in various datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_integer(c(\"1\", \"231\", \".\", \"456\"), na = \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When parsing fails we get a warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- parse_integer(c(\"123\", \"345\", \"abc\", \"123.45\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we get too many warning we can use `problems()` to list all of them:\n",
    "problems(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Writing to a file\n",
    "Similar to how we read a file from disk we can write one. We can use `write_csv()`, `write_delim()`, and other functions depending on our need. Earlier in this notebook we created `calDf`, a data frame from an inline text which was delimited by \"|\". Let's write this data frame to file, we can use any of the common delimiters, I pick CSV here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_csv(calDf, path = \"../tmp/calDf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the first 3 rows from disk\n",
    "calDfNew <- read_csv(\"../tmp/calDf.csv\", n_max = 3)\n",
    "calDfNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Read Excel files\n",
    "We will be using package readxl from tidyverse. readxl comes with a function some sample files, we can access to a list of these files by `readxl_example()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readxl_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the path for one of these sample files by giving the name of the sample to `readxl_example()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsExamplePath <- readxl_example('datasets.xlsx')\n",
    "xlsExamplePath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object is nothing but a path to the file, now having this path we can check out the sheets names with `excel_sheets()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_sheets(xlsExamplePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and read any of these sheets into a data frame by `read_excel()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcarsDf <- read_excel(xlsExamplePath, sheet = 'mtcars')\n",
    "print(mtcarsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if `sheet` parameter is not specified it'll go to the default which is the first sheet.\n",
    "\n",
    "We can read only a subset of the cell by an Excel-specified notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_excel(xlsExamplePath, range = \"C1:E4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(read_excel(xlsExamplePath, range = cell_cols(\"B:D\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_excel(xlsExamplePath, range = \"mtcars!B1:D5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to an Excel file\n",
    "tidyverse doesn't have a package for writing to an Excel file. We will use `write.xlsx()` from **openxlsx**. This package needs to be installed and loaded. Follow the instructions on the setup notebook for installation.\n",
    "\n",
    "R base comes with sample data frames (e.g., iris, mtcars), let's write some of them into an Excel file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l <- list(iris = iris, mtcars = mtcars, chickwts = chickwts, quakes = quakes)\n",
    "openxlsx::write.xlsx(l, file = \"../tmp/datasets.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: `openxlsx::` is optional, just a good practice for showing that unlike all of the other packages used in this notebook `write.xlsx()` is not from tidyverse.\n",
    "\n",
    "### Other types of data\n",
    "* **haven** reads SPSS, Stata, and SAS files\n",
    "* **DBI**, along with a database specific backend (e.g. RMySQL, RSQLite, RPostgreSQL etc) allows you to run SQL queries against a database and return a data frame\n",
    "* For hierarchical data: use **jsonlite** for json, and **xml2** for XML"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
